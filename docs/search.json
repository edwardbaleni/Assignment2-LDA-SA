[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "This is a website for the submission of Assignment 2 for STA5073Z.\nGroup: Edward Baleni, Luke Barnes and Andrea Plumbley"
  },
  {
    "objectID": "Template.html#introduction",
    "href": "Template.html#introduction",
    "title": "Template",
    "section": "Introduction",
    "text": "Introduction\nThe aim of this assignment is to provide a descriptive analysis of the State of the Nation speeches in South Africa between 1994 and 2022. This descriptive analysis is performed using sentiment analysis and topic modelling. Sentiment analysis aims to describe the content of text in terms of its ‘emotions’ (REFERENCE). The purpose of performing sentiment analysis on these speeches is to identify the overall tone or emotion of the speech and identify how this might change over time or as presidents change. Topic modelling is a technique that aims to summarize text, in this case speeches, in terms of a number of topics. It is a way of categorizing speeches into different topics and identifying the main themes of a body of text (REFERENCE). This is of interest in order to identify what topics or themes are important in the context of the government of South Africa and how these themes or main topics may change over time or over different presidents.\nBefore the analysis is applied to the data a brief literature review will be given. Following this the data and any cleaning that was done will be discussed. The methods for performing sentiment analysis and topic modelling will be outlined. Finally the results of the analysis on the SONA speeches data will be presented and discussed.\nChat GPT was used as an aid to this assignment. The purpose of this was to experiment large language models and to assess Chat GPT’s ability to assist with the assignment. A brief summary of how well it did and how it responded to different prompts and guides in given in Appendix A (which can be found on Appendix A tab of this website)."
  },
  {
    "objectID": "Template.html#literature-review",
    "href": "Template.html#literature-review",
    "title": "Template",
    "section": "Literature Review",
    "text": "Literature Review\n\nSentiment Analysis\n\n\nTopic Modelling"
  },
  {
    "objectID": "Template.html#data",
    "href": "Template.html#data",
    "title": "Template",
    "section": "Data",
    "text": "Data\nAs mentioned, the data for this analysis is a collection of 36 speeches delivered as State of the Nation Addresses between 1994 and 2022. These speeches were delivered by 6 different presidents: de Klerk, Mandela, Mbeki, Motlanthe, Zuma and Ramaphosa.\nThis data needed to be cleaned before sentiment analysis or topic modelling could be done. The data was cleaned by removing punctuation marks and numbers from the speeches. Stop words, which are common words such as ‘the’, ‘and’ and ‘they’ were also removed from the speeches.\nIn order to perform sentiment analysis the speeches needed to be tokenized into shorter parts such as bigrams and words in order to assess the sentiment of each smaller part and then aggregate these sentiments to understand the sentiment of the speech as a whole. The speeches are tokenized first into sentences and then into words using the unnest_tokens() function in R.\n\nExplain why bigrams were necessary and how this worked - Were stop words not removed?? Because we need not and no etc\n\nHow was data structured for topic modelling??"
  },
  {
    "objectID": "Template.html#methods",
    "href": "Template.html#methods",
    "title": "Template",
    "section": "Methods",
    "text": "Methods\n\nSentiment Analysis\nIn order to perform sentiment analysis, sentiment lexicons are used. These lexicons contain many words which are labelled according to their sentiment. The main lexicon that was made use of here for analysis was the bing dictionary which labels words as positive or negative. The affin dictionary gives each word a score between negative five and five, from negative to positive sentiments.\nIn order to get each words sentiment, the data frame containing individual words, with an associated president, year ans sentence ID is left joined with the bing lexicon in order to get their associated positive or negative sentiment. Because many of the words in the speeches are not in the dictionary, these words are assigned with a sentiment value of neutral instead of removing them from analysis. This is not an ideal situation as it may mean that words which are very emotively loaded are being assigned as neutral and so one could miss the true sentiment of a sentence or speech however it is better than removing all these words from the analysis completely.\nIn order to analyze the sentiment of different presidents we can consider each presidents most commonly used positive and negative words which can be found using filtering by president and filtering by positive or negative sentiment.\nIn addition one can consider how sentiment changes over time and by president by considering the number of positive and negative sentiment associated words and seeing how this changes over time. This can also be done using the filter() function and filtering by year. In this way one can see if the percentage of positive sentiment in a speech increased or decreased as well as identify the net sentiment of the SONA speeches over time.\n\nNEED TO ADD BIGRAMS SECTION OF SENTIMENT ANALYSIS\n\n\n\nTopic Modelling\nAdd topic modelling methods and explain LDA."
  },
  {
    "objectID": "Template.html#results-and-discussion",
    "href": "Template.html#results-and-discussion",
    "title": "Template",
    "section": "Results and Discussion",
    "text": "Results and Discussion\nHaving outlined the methods used to perform sentiment analysis and topic modelling, the results and analysis of the speeches is now given.\n\nSentiment Analysis\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\nnegative  neutral positive \n    4510    88544     7327 \n\n\n\n\n\n\n## Each Presidents Top 15 Most Frequent Positive words\n## Top 5 is highlighted\n\nP1 = wordsSentiment %>%\n  filter(president == \"Mandela\") %>%\n  filter(bing_sentiment == \"positive\") %>%\n  count(word) %>%\n  #filter(rank(desc(n)) <= 20) %>%\n  arrange(desc(n)) %>%\n  mutate(id = 1:dim(.)[1]) %>%\n  filter(id <= 15) %>%\n  ggplot(aes(reorder(word, n), n)) + geom_col(fill = \"purple\", col = \"black\") + \n  coord_flip() + \n  xlab(\" \") + ylab(\"Times Used in Speeches\") +\n  theme_bw(base_size = 12) +\n  gghighlight(id <= 6)\n\nP2 = wordsSentiment %>%\n  filter(president == \"Mbeki\") %>%\n  filter(bing_sentiment == \"positive\") %>%\n  count(word) %>%\n  arrange(desc(n)) %>%\n  mutate(id = 1:dim(.)[1]) %>%\n  filter(id <= 15) %>%\n  ggplot(aes(reorder(word, n), n)) + geom_col(fill = \"purple\", col = \"black\") + \n  coord_flip() + \n  xlab(\" \") + ylab(\"Times Used in Speeches\") +\n  theme_bw(base_size = 12) +\n  gghighlight(id <= 5)\n\nP3 = wordsSentiment %>%\n  filter(president == \"Motlanthe\") %>%\n  filter(bing_sentiment == \"positive\") %>%\n  count(word) %>%\n  #filter(id <= 15) %>%\n  arrange(desc(n)) %>%\n  mutate(id = 1:dim(.)[1]) %>%\n  filter(id <= 15) %>%\n  ggplot(aes(reorder(word, n), n)) + geom_col(fill = \"purple\", col = \"black\") + \n  coord_flip() + \n  xlab(\" \") + ylab(\"Times Used in Speech\") +\n  theme_bw(base_size = 12) +\n  gghighlight(id <= 5)\n\nP4 = wordsSentiment %>%\n  filter(president == \"Ramaphosa\") %>%\n  filter(bing_sentiment == \"positive\") %>%\n  count(word) %>%\n  #filter(id <= 15) %>%\n  arrange(desc(n)) %>%\n  mutate(id = 1:dim(.)[1]) %>%\n  filter(id <= 15) %>%\n  ggplot(aes(reorder(word, n), n)) + geom_col(fill = \"purple\", col = \"black\") + \n  coord_flip() + \n  xlab(\" \") + ylab(\"Times Used in Speeches\") +\n  theme_bw(base_size = 12) +\n  gghighlight(id <= 5)\n\nP5 = wordsSentiment %>%\n  filter(president == \"Zuma\") %>%\n  filter(bing_sentiment == \"positive\") %>%\n  count(word) %>%\n  #filter(rank(desc(n)) <= 20) %>%\n  arrange(desc(n)) %>%\n  mutate(id = 1:dim(.)[1]) %>%\n  filter(id <= 15) %>%\n  ggplot(aes(reorder(word, n), n)) + geom_col(fill = \"purple\", col = \"black\") + \n  coord_flip() + \n  xlab(\" \") + ylab(\"Times Used in Speeches\") +\n  theme_bw(base_size = 12) +\n  gghighlight(id <= 5)\n\nP6 = wordsSentiment %>%\n  filter(president == \"deKlerk\") %>%\n  filter(bing_sentiment == \"positive\") %>%\n  count(word) %>%\n  #filter(rank(desc(n)) <= 20) %>%\n  arrange(desc(n)) %>%\n  mutate(id = 1:dim(.)[1]) %>%\n  filter(id <= 15) %>%\n  ggplot(aes(reorder(word, n), n)) + geom_col(fill = \"purple\", col = \"black\") + \n  coord_flip() + \n  xlab(\" \") + ylab(\"Times Used in Speech\") +\n  theme_bw(base_size = 12) +\n  gghighlight(id <= 5)\n\nggarrange(P1, P2, P3, P4, P5, P6, ncol=3, nrow=2)"
  },
  {
    "objectID": "Template.html#conclusion",
    "href": "Template.html#conclusion",
    "title": "Template",
    "section": "Conclusion",
    "text": "Conclusion"
  },
  {
    "objectID": "Appendix.html",
    "href": "Appendix.html",
    "title": "Appendix",
    "section": "",
    "text": "This will contain the appendix of the report and maybe some code.\n\n2 + 2\n\n[1] 4"
  },
  {
    "objectID": "Use of ChatGPT.html",
    "href": "Use of ChatGPT.html",
    "title": "Appendix",
    "section": "",
    "text": "This will contain Chat GPT section.\n\n2 + 2\n\n[1] 4"
  }
]